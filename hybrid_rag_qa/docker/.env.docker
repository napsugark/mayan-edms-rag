# ============================================================
# RAG Container — .env.docker
# Copy to .env before running:  cp .env.docker .env
# ============================================================

# ----- Qdrant (local container, no auth needed) -----
QDRANT_ENDPOINT=http://qdrant:6333
# QDRANT_API_KEY=            # leave blank for local Qdrant

# ----- LLM backend -----
# Switch between "OLLAMA" and "AZURE_OPENAI"
MODEL_TO_USE=AZURE_OPENAI

# Ollama (when MODEL_TO_USE=OLLAMA)
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=llama3.1:8b

# Azure OpenAI (when MODEL_TO_USE=AZURE_OPENAI)
AZURE_OPENAI_ENDPOINT=https://YOUR_RESOURCE.openai.azure.com/
AZURE_OPENAI_API_KEY=your-azure-key-here
AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_API_VERSION=2024-06-01

# ----- Mayan EDMS (optional — for webhook/sync endpoints) -----
# MAYAN_URL=http://mayan-edms:8000
# MAYAN_API_TOKEN=your-mayan-token
# WEBHOOK_SECRET=your-webhook-secret

# ----- Langfuse (auto-configured — matches docker-compose init values) -----
LANGFUSE_PUBLIC_KEY=pk-lf-local-dev-public
LANGFUSE_SECRET_KEY=sk-lf-local-dev-secret
LANGFUSE_HOST=http://langfuse-web:3000
